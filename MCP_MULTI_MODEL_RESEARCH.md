# MCP Multi-Model Access & Delegation Research

**Date:** 2026-01-12
**Research Goal:** Find MCP servers with multi-model access, model delegation, and vision capabilities

---

## Executive Summary

Found 15+ relevant MCP server implementations with multi-model orchestration, task delegation, and vision capabilities. Key patterns emerged:

1. **Model Delegation via MCP Tools** - MCP servers expose AI models as callable tools
2. **Multi-Model Orchestration** - Coordinators route tasks across multiple model providers
3. **Vision Integration** - Multiple servers expose image/video analysis through MCP
4. **Agent-to-Agent Communication** - Bi-directional messaging patterns for sub-agent coordination

---

## üéØ Top 5 Most Relevant Projects

### 1. **BeehiveInnovations/pal-mcp-server** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** Multi-Model Orchestration Platform

**Key Features:**
- Allows Claude to coordinate with Gemini Pro, O3, GPT-5, and 50+ models
- Maintains conversation continuity across models
- Automatic model selection or explicit specification
- Vision capabilities across models
- Extended thinking modes

**Configuration Pattern:**
```json
{
  "DEFAULT_MODEL": "auto",  // Intelligent selection
  "providers": {
    "openrouter": true,  // Unified API for multiple models
    "gemini": true,
    "openai": true,
    "ollama": true  // Local deployment
  }
}
```

**Use Case:** Code review workflow where Claude reviews systematically, consults Gemini Pro for deeper analysis, gathers O3 perspectives, then creates unified action plan - all in one conversation.

**GitHub:** https://github.com/BeehiveInnovations/pal-mcp-server

---

### 2. **philschmid/gemini-mcp-server** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** Expose Gemini Models via MCP

**Key Features:**
- Exposes Gemini 2.5 Flash and 1.5 Pro as MCP tools
- Web search with Google grounding
- Vision capabilities (image analysis)
- STDIO and HTTP transport modes

**MCP Tools:**
```typescript
// Tool 1: Direct Gemini access
{
  name: "use_gemini",
  parameters: {
    prompt: string,  // Required
    model: string    // Optional, defaults to "gemini-2.5-flash-preview-05-20"
  }
}

// Tool 2: Web search with synthesis
{
  name: "web_search",
  parameters: {
    query: string,
    include_citations: boolean  // Optional, defaults to false
  }
}
```

**Deployment Modes:**
- **Local (STDIO):** Reads `GEMINI_API_KEY` from environment
- **Remote (HTTP):** Bearer token authentication on `http://0.0.0.0:8000/mcp/`

**Vision Support:** Mentioned as feature flag for "GitHub Copilot chat vision in Claude"

**GitHub:** https://github.com/philschmid/gemini-mcp-server

---

### 3. **yiwenlu66/mu-mcp** ‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** LLM-Driven Model Selection

**Key Features:**
- Dynamic model switching mid-conversation
- Agent (Claude) intelligently picks models based on:
  - Task complexity
  - Performance vs cost trade-offs
  - Specific model strengths
  - Context window needs
  - Image support requirements
- Persistent conversation storage
- Curated model registry with documented capabilities

**Configuration:**
```json
{
  "mcpServers": {
    "mu-mcp": {
      "command": "uv",
      "args": ["--directory", "/path/to/mu-mcp", "run", "python", "server.py"],
      "env": {
        "OPENROUTER_API_KEY": "your-key-here"
      }
    }
  }
}
```

**Usage Pattern:**
```
User: "Use gpt-5 to explain quantum computing"
User: "Chat with o3-mini using high reasoning effort"
```

The agent sees available models and autonomously selects optimal choice.

**Philosophy:** "Gets out of the way" - treats AI agent as intelligent decision-maker, not hardcoded workflows.

**GitHub:** https://github.com/yiwenlu66/mu-mcp

---

### 4. **dvcrn/mcp-server-subagent** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** Task Delegation to Sub-Agents

**Key Features:**
- Bi-directional communication between parent and sub-agents
- Asynchronous message-passing architecture
- Full auditability with persistent logs
- Dynamic tool generation per sub-agent

**MCP Tools (Per Sub-Agent):**
```typescript
// Execution
run_subagent_<name>(input: string) ‚Üí { runId: UUID }
check_subagent_status(runId: UUID) ‚Üí { status, metadata, questions }
get_subagent_logs(runId: UUID) ‚Üí { logs: string[] }
update_subagent_status(runId: UUID, status: string, summary?: string)

// Bi-directional Communication
ask_parent(runId: UUID, question: string) ‚Üí { messageId: UUID }
reply_subagent(runId: UUID, messageId: UUID, answer: string)
check_message_status(runId: UUID, messageId: UUID) ‚Üí { hasAnswer: boolean, answerContent?: string }
```

**Communication Flow:**
1. Sub-agent invokes `ask_parent` with context
2. Parent monitors via `check_subagent_status` and discovers pending questions
3. Parent responds using `reply_subagent`
4. Sub-agent polls `check_message_status` with configurable sleep intervals

**Persistence:**
- `.log` - real-time output stream
- `.prompt.md` - input prompt content
- `.meta.json` - execution metadata including all communication messages

**Use Case:** Complex multi-step tasks delegated to specialized agents with parent oversight and intervention capability.

**GitHub:** https://github.com/dvcrn/mcp-server-subagent

---

### 5. **MCP-Mirror/Dicklesworthstone_llm_gateway_mcp_server** ‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** LLM Gateway for Cost-Effective Task Delegation

**Key Features:**
- Intelligent delegation from high-capability models to cost-effective LLMs
- 90% cost reduction for routine tasks
- Multi-provider abstraction (OpenAI, Anthropic, Google, DeepSeek)
- Caching and fallback mechanisms

**Delegation Workflow:**
1. **Agent Request:** Claude identifies task suitable for delegation
2. **MCP Tool Invocation:** Agent calls gateway tools via MCP
3. **Optimization Layer:** Gateway analyzes task requirements
4. **Provider Routing:** Routes to selected LLM (Gemini Flash, GPT-4o-mini, DeepSeek)
5. **Result Return:** Standardized response with caching

**Economic Impact:**
- Summarizing 100-page document: $4.50 (Claude) ‚Üí $0.45 (Gemini Flash)
- 90% cost savings while maintaining quality

**Configuration:**
```bash
# API Credentials
OPENAI_API_KEY=...
ANTHROPIC_API_KEY=...
GEMINI_API_KEY=...
DEEPSEEK_API_KEY=...

# Server Parameters
SERVER_HOST=127.0.0.1
SERVER_PORT=8013

# Optimization
CACHE_ENABLED=true
CACHE_TTL=3600
PROVIDER_TIMEOUT=30
```

**Routing Criteria:**
- Task complexity assessment
- Budget constraints
- Performance priority (speed vs accuracy)
- Historical model performance data

**GitHub:** https://github.com/MCP-Mirror/Dicklesworthstone_llm_gateway_mcp_server

---

## üñºÔ∏è Vision & Image Analysis MCP Servers

### 6. **tan-yong-sheng/ai-vision-mcp** ‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** AI-Powered Image & Video Analysis

**Provider Support:**
- Google Gemini API (simple, API key only)
- Vertex AI (production, service account + GCS)

**MCP Tools:**
```typescript
// 1. Single image analysis
analyze_image(image: URL | path | base64, prompt: string)

// 2. Multi-image comparison (2-4 images)
compare_images(images: Array<URL | path | base64>, prompt: string)

// 3. Object detection with bounding boxes
detect_objects_in_image(image: URL | path | base64) ‚Üí {
  annotated_image: string,
  detections: Array<{label, bbox, confidence}>
}

// 4. Video analysis
analyze_video(video: URL | path) // YouTube URLs and local files
```

**Configuration Hierarchy:**
```bash
# Provider Selection
IMAGE_PROVIDER=gemini  # or vertexai
VIDEO_PROVIDER=gemini

# Task-Specific Optimization
TEMPERATURE_FOR_DETECT_OBJECTS_IN_IMAGE=0.0  # Deterministic
TEMPERATURE_FOR_ANALYZE_IMAGE=0.7            # Creative

# Error Resilience
RETRY_MAX_ATTEMPTS=3
RETRY_BACKOFF_FACTOR=2
```

**Error Handling:**
- Input validation via Zod schemas
- Automatic retry with exponential backoff
- File size/format constraint handling

**GitHub:** https://github.com/tan-yong-sheng/ai-vision-mcp

---

### 7. **groundlight/mcp-vision** ‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** HuggingFace Computer Vision Models via MCP

**MCP Tools:**
```typescript
// Zero-shot object detection
locate_objects(
  image_path: URL | path,
  candidate_labels: string[],
  hf_model?: string  // Default: "google/owlvit-large-patch14"
) ‚Üí ObjectDetectionResult[]

// Focused analysis with cropping
zoom_to_object(
  image_path: URL | path,
  label: string,
  hf_model?: string
) ‚Üí MCPImage | null
```

**Image Handling:**
- Remote URLs supported
- Local file paths supported
- Returns MCPImage format (MCP standard)

**Architecture:**
- Docker container isolation
- HuggingFace pre-trained models (on-demand download)
- CPU-optimized alternatives available

**Use Case:** Zero-shot detection without training data - just provide candidate labels.

**GitHub:** https://github.com/groundlight/mcp-vision

---

### 8. **GongRzhe/opencv-mcp-server**
**Purpose:** OpenCV Image & Video Processing

**Key Features:**
- Image manipulation
- Real-time object detection
- Video tracking
- Python package

**GitHub:** https://github.com/GongRzhe/opencv-mcp-server

---

### 9. **mario-andreschak/mcp-image-recognition**
**Purpose:** Image Recognition via Anthropic & OpenAI Vision APIs

**Key Features:**
- Image description
- Text extraction (OCR)
- Uses Anthropic and OpenAI vision endpoints

**GitHub:** https://github.com/mario-andreschak/mcp-image-recognition

---

## ü§ñ Multi-Agent & Orchestration

### 10. **askbudi/roundtable** ‚≠ê‚≠ê‚≠ê
**Purpose:** Unified Multi-Assistant Platform

**Key Features:**
- Zero-configuration auto-discovery
- Unifies Claude Code, Cursor, Gemini
- Intelligent task delegation
- Coordinated AI collaboration

**GitHub:** https://github.com/askbudi/roundtable

---

### 11. **rinadelph/Agent-MCP**
**Purpose:** Multi-Agent Systems Framework

**Key Features:**
- Coordinated AI collaboration via MCP
- Tools to spawn specialized agents
- Task delegation to experts

**GitHub:** https://github.com/rinadelph/Agent-MCP

---

### 12. **joohnnie/mcp-agent**
**Purpose:** Python Multi-Agent System

**Key Features:**
- Intelligent Agent System
- Subagents with orchestration
- Delegated work to specialized agents

**GitHub:** https://github.com/joohnnie/mcp-agent

---

### 13. **da1z/subagents**
**Purpose:** Subagents for Complex Tasks

**Key Features:**
- Delegates complex, multi-step tasks
- Specialized agents
- Optimized for Cursor integration

**GitHub:** https://github.com/da1z/subagents

---

### 14. **lastmile-ai/mcp-agent**
**Purpose:** Expose AI Workflows as MCP Servers

**Key Features:**
- Complex AI applications as MCP servers
- Agent-to-agent delegation patterns
- Sophisticated workflow orchestration

**GitHub:** https://github.com/lastmile-ai/mcp-agent

---

## üìö Supporting Libraries & Infrastructure

### 15. **BerriAI/litellm** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** Unified Interface for 100+ LLMs

**Key Features:**
- Dynamic routing
- Load balancing
- Fallback logic
- Cost optimization

**GitHub:** https://github.com/BerriAI/litellm

---

### 16. **nilsherzig/LLMRouter**
**Purpose:** Intelligent LLM Routing

**Routes Based On:**
- Task complexity
- Cost optimization
- Performance metrics

**GitHub:** https://github.com/nilsherzig/LLMRouter

---

### 17. **aurelio-labs/semantic-router**
**Purpose:** Semantic Vector Space Routing

**Key Features:**
- Fast decision-making layer
- Routes based on prompt meaning/intent
- Semantic vector space analysis

**GitHub:** https://github.com/aurelio-labs/semantic-router

---

### 18. **google-gemini/gemini-cli** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Purpose:** Official Gemini CLI with MCP Support

**MCP Integration:**
- Configure MCP servers in `~/.gemini/settings.json`
- Namespace-referenced with `@` symbol
- Extends Gemini with custom tools

**Usage Examples:**
```bash
> @github List my open pull requests
> @slack Send a summary of today's commits to #dev channel
> @database Run a query to find inactive users
```

**Extended Capabilities:**
- Media generation (Imagen, Veo, Lyria) via MCP servers
- Enterprise/specialized workflows
- Functions as extensible platform

**Configuration:**
```json
{
  "mcpServers": {
    "github": { /* ... */ },
    "slack": { /* ... */ },
    "database": { /* ... */ }
  }
}
```

**Documentation:** `/docs/tools/mcp-server.md`

**GitHub:** https://github.com/google-gemini/gemini-cli

---

## üèóÔ∏è Official MCP Resources

### 19. **modelcontextprotocol/specification**
**Purpose:** Official MCP Specification

**Defines:**
- How AI models connect to external data
- Tool exposure patterns
- Communication protocols

**GitHub:** https://github.com/modelcontextprotocol/specification

---

### 20. **modelcontextprotocol/typescript-sdk**
**Purpose:** Official TypeScript MCP SDK

**Use For:**
- Creating MCP clients
- Creating MCP servers
- Routing layer building blocks

**GitHub:** https://github.com/modelcontextprotocol/typescript-sdk

---

### 21. **modelcontextprotocol/python-sdk**
**Purpose:** Official Python MCP SDK

**Use For:**
- Agentic frameworks
- Tool and context management
- Server implementation

**GitHub:** https://github.com/modelcontextprotocol/python-sdk

---

### 22. **modelcontextprotocol/servers**
**Purpose:** Reference MCP Server Implementations

**Includes:**
- GitHub integration
- Slack integration
- Postgres integration
- Google Drive
- Google Maps
- Multi-model utilities

**Use For:**
- Learning MCP patterns
- Tool exposure examples
- Multi-model consumption

**GitHub:** https://github.com/modelcontextprotocol/servers

---

## üé® Key Patterns Identified

### Pattern 1: Model-as-Tool
Expose AI models as MCP tools that other models can call:

```typescript
{
  name: "use_gemini",
  description: "Delegate task to Gemini model",
  parameters: {
    prompt: { type: "string", required: true },
    model: { type: "string", default: "gemini-2.5-flash" }
  }
}
```

**Examples:** philschmid/gemini-mcp-server, pal-mcp-server

---

### Pattern 2: Intelligent Gateway
Route requests through optimization layer:

```
Claude Request
    ‚Üì
[Task Analysis]
    ‚Üì
[Complexity: Low, Cost: Priority]
    ‚Üì
Route to Gemini Flash (90% savings)
    ‚Üì
Cached Response
    ‚Üì
Return to Claude
```

**Examples:** Dicklesworthstone/llm_gateway, LiteLLM, LLMRouter

---

### Pattern 3: Sub-Agent Delegation
Parent coordinates specialized sub-agents:

```
Parent Agent (Claude)
    ‚Üì
[run_subagent_coder] ‚Üí Code Generation Task
    ‚Üì [ask_parent]
[Question: "Which API version?"]
    ‚Üì [reply_subagent]
[Answer: "Use v2.0"]
    ‚Üì
Sub-agent completes with context
```

**Examples:** dvcrn/mcp-server-subagent, da1z/subagents

---

### Pattern 4: Multi-Modal Vision
Expose vision capabilities via MCP:

```typescript
// Single image
analyze_image(image, "Describe this UI element")

// Comparison
compare_images([before, after], "What changed?")

// Detection
detect_objects_in_image(screenshot) ‚Üí {
  objects: [{label: "button", bbox: [x,y,w,h]}]
}

// Video
analyze_video(youtube_url, "Summarize this tutorial")
```

**Examples:** ai-vision-mcp, groundlight/mcp-vision, opencv-mcp-server

---

### Pattern 5: Orchestration Coordinator
Central coordinator manages model selection:

```typescript
class Orchestrator {
  async selectModel(task: Task): Promise<ModelProvider> {
    const complexity = analyzeComplexity(task);
    const budget = getBudgetConstraints();
    const capabilities = task.requiresVision ? ['vision'] : [];

    if (complexity === 'high') return 'claude-opus-4';
    if (capabilities.includes('vision')) return 'gemini-2.5-pro';
    if (budget === 'optimize') return 'gemini-flash';

    return 'auto'; // Let agent decide
  }
}
```

**Examples:** pal-mcp-server, mu-mcp, roundtable

---

## üîß Implementation Recommendations

### For Your Komplete Kontrol CLI Project

Based on research findings, here's the recommended architecture:

#### 1. **Adopt Model-as-Tool Pattern**
Create MCP server that exposes Gemini as callable tool:

```typescript
// src/mcp/servers/gemini-delegate.ts
export const geminiTools = {
  use_gemini: {
    description: "Delegate task to Gemini 2.5 Flash or Pro",
    parameters: {
      prompt: { type: "string", required: true },
      model: {
        type: "string",
        enum: ["gemini-2.5-flash", "gemini-2.5-pro"],
        default: "gemini-2.5-flash"
      },
      requiresVision: { type: "boolean", default: false }
    },
    handler: async (params) => {
      // Use existing gemini-cli integration
      return await geminiChat(params.prompt, params.model);
    }
  },

  analyze_with_gemini_vision: {
    description: "Analyze image with Gemini vision",
    parameters: {
      image_path: { type: "string", required: true },
      prompt: { type: "string", required: true }
    },
    handler: async (params) => {
      return await geminiAnalyzeFile(params.image_path, params.prompt);
    }
  }
};
```

#### 2. **Implement Task Complexity Router**
Analyze tasks and route automatically:

```typescript
// src/core/providers/task-router.ts
export class TaskRouter {
  async route(prompt: string, context: Context): Promise<Provider> {
    const complexity = this.analyzeComplexity(prompt);
    const hasImages = context.images?.length > 0;
    const budget = context.budget || 'balanced';

    // High complexity ‚Üí Claude
    if (complexity > 0.8) {
      return 'anthropic';
    }

    // Vision required ‚Üí Gemini
    if (hasImages) {
      return 'gemini-vision';
    }

    // Budget optimize ‚Üí Gemini Flash
    if (budget === 'optimize' && complexity < 0.5) {
      return 'gemini-flash';
    }

    // Default
    return 'anthropic';
  }

  private analyzeComplexity(prompt: string): number {
    // Simple heuristics
    const indicators = {
      hasCode: /```/.test(prompt),
      isLongForm: prompt.length > 1000,
      requiresReasoning: /analyze|explain|reason|why/.test(prompt.toLowerCase()),
      isCreative: /write|create|generate|design/.test(prompt.toLowerCase())
    };

    let score = 0;
    if (indicators.hasCode) score += 0.3;
    if (indicators.isLongForm) score += 0.2;
    if (indicators.requiresReasoning) score += 0.3;
    if (indicators.isCreative) score += 0.2;

    return Math.min(score, 1.0);
  }
}
```

#### 3. **Integrate with Existing Gemini MCP**
Enhance current gemini-cli MCP integration:

```typescript
// src/mcp/integrations/gemini.ts
import { geminiChat, geminiAnalyzeFile } from '../tools/gemini';

export class GeminiMCPIntegration {
  async chat(prompt: string, model?: string): Promise<string> {
    return await geminiChat(prompt, model);
  }

  async analyzeImage(imagePath: string, prompt?: string): Promise<string> {
    return await geminiAnalyzeFile(imagePath, prompt);
  }

  async webSearch(query: string, includeCitations = false): Promise<string> {
    // Use gemini-cli's native google search
    return await geminiChat(
      `Search the web for: ${query}${includeCitations ? ' (include citations)' : ''}`,
      'gemini-2.5-flash'
    );
  }
}
```

#### 4. **Add Cost Tracking**
Monitor savings from delegation:

```typescript
// src/core/analytics/cost-tracker.ts
export class CostTracker {
  private costs = {
    'claude-opus-4': 15.00,      // per 1M input tokens
    'claude-sonnet-4': 3.00,
    'gemini-2.5-pro': 1.25,
    'gemini-2.5-flash': 0.075
  };

  track(provider: string, tokens: number): void {
    const cost = (tokens / 1_000_000) * this.costs[provider];

    // Log and aggregate
    this.logger.info(`Provider: ${provider}, Tokens: ${tokens}, Cost: $${cost.toFixed(4)}`);
  }

  getSavingsReport(): Report {
    // Calculate savings from routing to cheaper models
    const baseline = this.totalTokens * this.costs['claude-opus-4'] / 1_000_000;
    const actual = this.totalCost;
    const savings = baseline - actual;
    const savingsPercent = (savings / baseline) * 100;

    return {
      baseline: `$${baseline.toFixed(2)}`,
      actual: `$${actual.toFixed(2)}`,
      savings: `$${savings.toFixed(2)}`,
      savingsPercent: `${savingsPercent.toFixed(1)}%`
    };
  }
}
```

#### 5. **Configuration Schema**
Add model delegation config:

```json
// .claude/config.json
{
  "model_delegation": {
    "enabled": true,
    "default_router": "auto",  // or "claude-only", "gemini-only"
    "complexity_threshold": 0.5,
    "budget_mode": "balanced",  // or "optimize", "performance"
    "vision_provider": "gemini",
    "cache_responses": true,
    "fallback_chain": ["gemini-flash", "gemini-pro", "claude-sonnet"]
  },
  "cost_tracking": {
    "enabled": true,
    "report_frequency": "daily"
  }
}
```

---

## üìä Comparison Matrix

| Feature | pal-mcp | philschmid/gemini | mu-mcp | subagent | llm-gateway | ai-vision | groundlight/vision |
|---------|---------|-------------------|--------|----------|-------------|-----------|-------------------|
| Multi-Model | ‚úÖ 50+ | ‚úÖ Gemini | ‚úÖ OpenRouter | ‚úÖ Any | ‚úÖ 4+ | ‚úÖ Gemini/Vertex | ‚úÖ HuggingFace |
| Vision | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ |
| Auto Selection | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå | ‚ùå |
| Cost Optimization | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå |
| Bi-directional | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚ùå | ‚ùå |
| Persistent State | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| Web Search | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| Video Analysis | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚ùå |
| Zero-Shot Detection | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| Language | Multiple | Python | Python | Various | Python | TypeScript | Python |
| Transport | STDIO/HTTP | STDIO/HTTP | STDIO | STDIO | HTTP | STDIO | Docker |
| Maturity | Active | Active | Active | Active | Active | Active | Active |

---

## üöÄ Quick Start Templates

### Template 1: Simple Gemini Delegation
```typescript
// Minimal implementation
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { callGemini } from './gemini-api';

const server = new Server({
  name: 'gemini-delegate',
  version: '1.0.0'
});

server.tool('use_gemini', async ({ prompt, model = 'gemini-2.5-flash' }) => {
  const response = await callGemini(prompt, model);
  return { content: [{ type: 'text', text: response }] };
});

server.start();
```

### Template 2: Vision Analysis
```typescript
import { analyzeFile } from './gemini-api';

server.tool('analyze_image', async ({ image_path, prompt }) => {
  const analysis = await analyzeFile(image_path, prompt || 'Describe this image');
  return { content: [{ type: 'text', text: analysis }] };
});
```

### Template 3: Intelligent Router
```typescript
server.tool('smart_completion', async ({ prompt, context }) => {
  const router = new TaskRouter();
  const provider = await router.route(prompt, context);

  switch (provider) {
    case 'gemini-flash':
      return await callGemini(prompt, 'gemini-2.5-flash');
    case 'gemini-pro':
      return await callGemini(prompt, 'gemini-2.5-pro');
    default:
      return await callClaude(prompt);
  }
});
```

---

## üìñ Further Reading

### Official Documentation
- [MCP Specification](https://spec.modelcontextprotocol.io/)
- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)
- [Gemini CLI Docs](https://github.com/google-gemini/gemini-cli/tree/main/docs)

### Community Resources
- [Awesome MCP Servers](https://github.com/wong2/awesome-mcp-servers)
- [MCP Server Examples](https://github.com/punkpeye/awesome-mcp-servers)

### Related Technologies
- [LiteLLM](https://github.com/BerriAI/litellm) - Multi-LLM router
- [Semantic Router](https://github.com/aurelio-labs/semantic-router) - Intent-based routing
- [LLMRouter](https://github.com/nilsherzig/LLMRouter) - Task complexity routing

---

## üéØ Next Steps

1. **Choose Implementation Pattern**
   - Start with Model-as-Tool (simplest)
   - Add Intelligent Router (medium complexity)
   - Consider Sub-Agent pattern for complex workflows

2. **Integrate with Existing Code**
   - Enhance current gemini-cli MCP integration
   - Add task complexity analysis
   - Implement cost tracking

3. **Test & Iterate**
   - Start with simple delegation (summaries, searches)
   - Gradually add vision capabilities
   - Monitor cost savings and accuracy

4. **Scale Up**
   - Add more providers (GPT, O3, local Ollama)
   - Implement caching and fallbacks
   - Build agent orchestration for complex tasks

---

**End of Research Document**
